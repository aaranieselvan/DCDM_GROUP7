---
title: "datacleaning"
output: html_document
date: "2024-12-18"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Data cleaning and collating 
```{r}
##Install tidyverse package
library(tidyverse)

#Define the correct field order from the IMPC_SOP.csv file
sop_file <- "~/Desktop/DCDM_Group7/originals/IMPC_SOP.csv" #path to IMPC_SOP
sop_data <- read.csv(sop_file, header = TRUE) 

# Extract and clean the correct field names (standardized to lowercase)
correct_fields <- tolower(trimws(sop_data[[1]]))  # Lowercase and remove extra spaces

# Set the path to the folder containing all 140k files
data_path <- "~/Desktop/DCDM_Group7/originals/7/"

# List all files in the folder
file_list <- list.files(path = data_path, pattern = "\\.csv$", full.names = TRUE)

# Creata an empty list to store data
combined_data <- list()

```


##Create a loop to process each file 

```{r}
for (file in file_list) {
  # Read the file
  data <- read.csv(file, header = FALSE, col.names = c("field", "value"))
  
  # Clean up the 'field' names: lowercase and remove spaces
  data$field <- tolower(trimws(data$field))
  
  # Transpose the 'value' column so that fields become column names
  reshaped_data <- t(data$value) %>%
    as.data.frame() %>%
    setNames(data$field)
  
  # Ensure all columns are in the correct order
  # Add missing columns with NA
  missing_fields <- setdiff(correct_fields, names(reshaped_data))  # Find fields that are missing
  
  
  # Reorder columns to match the correct field order
  final_data <- reshaped_data %>%
    select(all_of(correct_fields))
  
  # Append to the list
  combined_data[[length(combined_data) + 1]] <- final_data
}
```

##Combine all data frames into one
```{r}
final_combined_data <- bind_rows(combined_data)

# Write the combined data to a single CSV file
write.csv(final_combined_data, "combined_output.csv", row.names = FALSE)
```


##Validate string length ( 15 characters) in analysis id
```{r}
# Define the function 

validate_analysis_id <- function (x, dataType, min_val, max_val) {
  if (tolower(dataType) == "string") {
    invalid_analysis_id <- which(sapply(x, nchar) < min_val | sapply (x, nchar) > max_val)
    return(invalid_analysis_id)
  } 
}
  
# Call the function 
  
invalid_analysis_id <- validate_analysis_id(final_combined_data$analysis_id, "string", 15, 15)

#Print results 
print(invalid_analysis_id)

# The returned results, is named_integer (0). This means that all strings are valid, and have the lengths defined in the SOP file. 
```

##Validate string length for gene accession id 
```{r}
# Define the function 
validate_gene_accession_id <- function (x, dataType, min_val, max_val) {
  if (tolower(dataType) == "string") {
    invalid_gene_accession_id <- which(sapply(x, nchar) < min_val | sapply (x, nchar) > max_val)
    return(invalid_gene_accession_id)
  } 
}
  
# Call the function 
invalid_gene_accession_id <- validate_gene_accession_id(final_combined_data$gene_accession_id, "string", 9, 11)

#Print results 
print(invalid_gene_accession_id)

# The returned results, is named_integer (0). This means that all strings are valid, and have the lengths defined in the SOP file.

```

##Validate string length for gene_symbol 
```{r}
# Define the function 
validate_gene_symbol <- function (x, dataType, min_val, max_val) {
  if (tolower(dataType) == "string") {
    invalid_gene_symbol <- which(sapply(x, nchar) < min_val | sapply (x, nchar) > max_val)
    return(invalid_gene_symbol)
  } 
}
  
# Call the function 
invalid_gene_symbol <- validate_gene_symbol(final_combined_data$gene_symbol, "string", 1, 13)

#Print results 
print(invalid_gene_symbol)

# The returned results, is named_integer (0). This means that all strings are valid, and have the lengths defined in the SOP file.
```

##Validate string length for parameter_id 
```{r}
# Define the function 
validate_parameter_id <- function (x, dataType, min_val, max_val) {
  if (tolower(dataType) == "string") {
    invalid_parameter_id <- which(sapply(x, nchar) < min_val | sapply (x, nchar) > max_val)
    return(invalid_parameter_id)
  } 
}
  
# Call the function 
invalid_parameter_id <- validate_parameter_id (final_combined_data$parameter_id, "string", 15, 18)

#Print results 
print(invalid_parameter_id)

# The returned results, is named_integer (0). This means that all strings are valid, and have the lengths defined in the SOP file.
```

##Validate parameter_name 
```{r}
# Define the function 
validate_parameter_name <- function (x, dataType, min_val, max_val) {
  if (tolower(dataType) == "string") {
    invalid_parameter_name <- which(sapply(x, nchar) < min_val | sapply (x, nchar) > max_val)
    return(invalid_parameter_name)
  } 
}
  
# Call the function 
invalid_parameter_name <- validate_parameter_name(final_combined_data$parameter_name, "string", 2, 74)

#Print results 
print(invalid_parameter_name)

# The returned results, is named_integer (0). This means that all strings are valid, and have the lengths defined in the SOP file.
```

##Validate the mouse life stage 
```{r}
# Define the function 
validate_mouse_life_stage <- function (x, field_name) {
  if (field_name == "mouse_life_stage") {
    valid_mouse_life_stage <- c("E12.5", "E15.5", "E18.5", "E9.5", 
      "Early adult", "Late adult", "Middle aged adult")
    invalid_mouse_life_stage <- which(!(x %in% valid_mouse_life_stage))
    return(invalid_mouse_life_stage)
  }
}

# Call the function 
invalid_mouse_life_stage <- validate_mouse_life_stage(final_combined_data$mouse_life_stage, "mouse_life_stage")

#Print the invalid rows 
print(invalid_mouse_life_stage)

# Print the total number of invalid mouse strains
cat("Total number of invalid mouse life stages:", length(invalid_mouse_life_stage))

# The results show there are zero entries with invalid life stages. 
```


##Validate p-value (float) 
```{r}
# Define the function 
validate_p_value <- function (x, min_val, max_val) {
  x <- as.numeric(x)
  invalid_p_value <- which(as.numeric(x) < min_val |
                             as.numeric(x) > max_val)
  return(invalid_p_value)
}
  
# Call the function 
invalid_p_value <- validate_p_value(final_combined_data$pvalue, 0, 1)

#Print results 
#print(invalid_p_value) #this will print the number of rows 

#Print the total number of invalud p-values 
cat("Total number of invalid p-values:", length(invalid_p_value))

# The total entries of invalid p-values is 813. This means that 813 rows are greater than or lower than 0 or 1.

#Final combined data with the removed invalid entries 
cleaned_mouse_data <- final_combined_data[-invalid_p_value, ]

#Prints the final number of rows remaining after removing invalid cases : 142066
cat("Number of rows after removing invalid mouse strains:", nrow(cleaned_mouse_data))

#Save the output file 
write.csv(cleaned_mouse_data, "cleaned_mouse_data.csv", row.names = FALSE)



```

##Validate mouse strain 

```{r}
# Define the function 
validate_mouse_strain <- function (x, field_name) {
  if (field_name == "mouse_strain") {
    valid_mouse_strains <- c("C57BL", "B6J", "C3H", "129SV")
    invalid_mouse_strain <- which(!(x %in% valid_mouse_strains))
    return(invalid_mouse_strain)
  }
}

# Call the function 
invalid_mouse_strain <- validate_mouse_strain(cleaned_mouse_data$mouse_strain, "mouse_strain")

#Print the invalid rows 
print(invalid_mouse_strain)

# Print the total number of invalid mouse strains
cat("Total number of invalid mouse strain:", length(invalid_mouse_strain))

# The results show there are 1135 invalid mouse strain entries. There are 1135 strains that do not match the required stages in the SOP file. 

#Final combined data with the removed invalid entries 
clean_final_data <- cleaned_mouse_data[-invalid_mouse_strain, ]

#Prints the final number of rows remaining after removing invalid cases : 140931
cat("Number of rows after removing invalid mouse strains:", nrow(clean_final_data))

write.csv(clean_final_data, "clean_final_data.csv", row.names = FALSE)
```

##Looking for Duplicates

```{r}
combined_output <- read.csv("~/Desktop/DCDM_GROUP7/combined_output.csv")
combined_output

# Find duplicate rows
duplicates <- duplicated(combined_output)

# View duplicate rows
duplicate_rows <- combined_output[duplicates, ]
print(duplicate_rows)

```

```{r}
# Replace 'column_name' with the name of the column (analysis id)
duplicates_in_column <- combined_output[duplicated(combined_output$analysis_id), ]
print(duplicates_in_column)
```

#Cleaning Disease information file

```{r}
#install.packages("tibble")
library(tibble)
```

##Remove the header in bash
```{bash}
sed '1D' Disease_information.txt > Disease_information_no_header.txt #remove header containing x

sed 's/"[0-9]*" "//g' Disease_information_no_header.txt > Disease_information_numbers_removed.txt #remove numbers in quotations

sed 's/"//g' Disease_information_numbers_removed.txt > Disease_information_clean.txt #remove unnecessary quotations 
```

##Looping to assign correct columns
```{r}
# Function to process each line
process_line <- function(line) {
  # Split the line by commas
  split_line <- strsplit(line, ",")[[1]]
  
  # Check if the line has enough parts (at least 3 columns)
  if (length(split_line) >= 3) {
    # First column: everything before the first comma
    first_column <- split_line[1]
    
    # Last column: everything after the last comma
    last_column <- split_line[length(split_line)]
    
    # Second-to-last column: everything between the second-to-last and last comma
    second_last_column <- split_line[length(split_line)-1]
    
    # Remainder as the second column: everything else in between
    second_column <- paste(split_line[2:(length(split_line)-2)], collapse = ",")
    
    # Return as a named vector
    return(c(first_column = first_column, second_column = second_column, 
             second_last_column = second_last_column, last_column = last_column))
  } else {
    # If the line doesn't have enough columns, return as is
    return(c(first_column = split_line[1], second_column = "", 
             second_last_column = "", last_column = ""))
  }
}

# Read the file line by line
lines <- readLines("~/Desktop/DCDM_GROUP7/outputs/Disease_information_clean.txt")

# Apply the function to each line and store results in a data frame
clean_disease <- t(sapply(lines, process_line))

# Convert the result to a data frame
clean_disease <- as.data.frame(clean_disease)

# View the processed data
View(clean_disease)
```

##Convert to tibble for easy visualisation
```{r}
clean_disease_correct_row_names = as_tibble(clean_disease, rownames = "disease_id")
View(clean_disease_correct_row_names)

#remove first column
clean_disease_correct_row_names2 = clean_disease_correct_row_names[, -1]
View(clean_disease_correct_row_names2)
```

##Rename the header with the correct column ids
```{r}
# Assuming 'processed_data' is the dataframe and the first row is the header
colnames(clean_disease_correct_row_names2) = clean_disease[1, ]   # Set the first row as the column names
clean_disease_info = clean_disease_correct_row_names2[-1, ]            # Remove the first row which is now the header

# View the updated dataframe
View(clean_disease_info)
sum(is.na(clean_disease_info)) #check for missing values
```

##Convert to csv
```{r}
write.csv(clean_disease_info, "Disease_information_clean.csv", row.names = FALSE)
```

#Cleaning Parameter Description File
```{bash}
sed '1D' IMPC_parameter_description.txt > IMPC_parameter_description_no_header.txt

sed 's/"[0-9]*" "//g' IMPC_parameter_description_no_header.txt > IMPC_parameter_description_numbers_removed.txt

sed -i '1s/.*/impcParameterOrigId, name, description, parameterId/' IMPC_parameter_description_numbers_removed.txt  #rename column header

sed 's/"//g' IMPC_parameter_description_numbers_removed.txt > IMPC_parameter_description_clean.txt #remove unnecessary quotations 
```

##Looping to assign correct columns
```{r}
#Function to process each line
process_line2 <- function(line) {
  # Split the line by commas
  split_line <- strsplit(line, ",")[[1]]
  
  # Check if the line has enough parts (at least 3 columns)
  if (length(split_line) >= 3) {
    # First column: everything before the first comma
    first_column <- split_line[1]
    
    # Last column: everything after the last comma
    last_column <- split_line[length(split_line)]
    
    # Second-to-last column: everything between the second-to-last and last comma
    second_last_column <- split_line[length(split_line)-1]
    
    # Remainder as the second column: everything else in between
    second_column <- paste(split_line[2:(length(split_line)-2)], collapse = ",")
    
    # Return as a named vector
    return(c(first_column = first_column, second_column = second_column, 
             second_last_column = second_last_column, last_column = last_column))
  } else {
    # If the line doesn't have enough columns, return as is
    return(c(first_column = split_line[1], second_column = "", 
             second_last_column = "", last_column = ""))
  }
}

# Read the file line by line
lines <- readLines("~/Desktop/DCDM_GROUP7/outputs/IMPC_parameter_description_clean.txt")

# Apply the function to each line and store results in a data frame
clean_PD <- t(sapply(lines, process_line2))

# Convert the result to a data frame
clean_PD <- as.data.frame(clean_PD)

# View the processed data
View(clean_PD)
```

##Convert to tibble for easy visualisation
```{r}
clean_PD_correct_row_names = as_tibble(clean_PD, rownames = "impcParameterOrigId")
View(clean_PD_correct_row_names)

#remove first column
clean_PD_correct_row_names = clean_PD_correct_row_names[, -1]
View(clean_PD_correct_row_names)
```

##Rename the header with the correct column ids
```{r}
# Assuming 'processed_data' is the dataframe and the first row is the header
colnames(clean_PD_correct_row_names) = clean_PD_correct_row_names[1, ]   # Set the first row as the column names
clean_parameter_description = clean_PD_correct_row_names[-1, ]            # Remove the first row which is now the header

# View the updated dataframe
View(clean_parameter_description)
sum(is.na(clean_parameter_description)) #check for missing values
```

##Replace missing values with NA
```{r}
clean_parameter_description[clean_parameter_description == " " ] <- NA #sets NA values
clean_parameter_description[is.na(clean_parameter_description)] <- "NA" #sets NA values into string
View(clean_parameter_description)
sum(is.na(clean_parameter_description)) #check for missing values
```

```{r}
write.csv(clean_parameter_description, "IMPC_parameter_description_clean.csv", row.names = FALSE)
```

#Cleaning Procedure file
```{bash}
sed 's/"[0-9]*" "//g' IMPC_procedure.txt > IMPC_procedure_numbers_removed.txt

sed -i '1s/.*/impcParameterOrigId, name, description, parameterId/' IMPC_procedure_numbers_removed.txt  #rename column header, removed procedureID as column contained no values

sed 's/"//g' IMPC_procedure_numbers_removed.txt > IMPC_procedure_clean.txt #remove unnecessary quotations 
```

##Looping to assign correct columns
```{r}
# Function to process each line
process_line3 <- function(line) {
  # Split the line by commas
  split_line <- strsplit(line, ",")[[1]]
  
  # Check if the line has enough parts (at least 3 columns)
  if (length(split_line) >= 3) {
    # First column: everything before the first comma
    first_column <- split_line[1]
    
    # Last column: everything after the last comma
    last_column <- split_line[length(split_line)]
    
    # Second-to-last column: everything between the second-to-last and last comma
    second_last_column <- split_line[length(split_line)-1]
    
    # Remainder as the second column: everything else in between
    second_column <- paste(split_line[2:(length(split_line)-2)], collapse = ",")
    
    # Return as a named vector
    return(c(first_column = first_column, second_column = second_column, 
             second_last_column = second_last_column, last_column = last_column))
  } else {
    # If the line doesn't have enough columns, return as is
    return(c(first_column = split_line[1], second_column = "", 
             second_last_column = "", last_column = ""))
  }
}

# Read the file line by line
lines <- readLines("~/Desktop/DCDM_GROUP7/outputs/IMPC_procedure_clean.txt")

# Apply the function to each line and store results in a data frame
clean_Pro <- t(sapply(lines, process_line3))

# Convert the result to a data frame
clean_Pro <- as.data.frame(clean_Pro)

# View the processed data
View(clean_Pro)
```

##Convert to tibble for easy visualisation
```{r}
clean_Pro_correct_row_names = as_tibble(clean_Pro, rownames = "name") #changes rowname to correct first column name
View(clean_Pro_correct_row_names)

#remove first column
clean_Pro_correct_row_names = clean_Pro_correct_row_names[, -1]
View(clean_Pro_correct_row_names)
```

##Rename the header with the correct column ids
```{r}
# Assuming 'processed_data' is the dataframe and the first row is the header
colnames(clean_Pro_correct_row_names) = clean_Pro_correct_row_names[1, ]   # Set the first row as the column names
clean_Pro = clean_Pro_correct_row_names[-1, ]            # Remove the first row which is now the header

# View the updated dataframe
View(clean_Pro)
sum(is.na(clean_Pro)) #check for missing values
```

##Replace NA values in a specific column with the string "NA"
```{r}
clean_Pro[clean_Pro == ' '] <- NA
clean_Pro[is.na(clean_Pro)] <- "NA"

# View the updated column
View(clean_Pro)
sum(is.na(clean_Pro)) #check for missing values
```

```{r}
write.csv(clean_Pro, "IMPC_procedure_clean.csv", row.names = FALSE)
```








